---
title: "Relative Informativity of Different Socio-Indexical Factors for Vowel Categorization"
subtitle: "An Analysis of the Nationwide Speech Corpus Vowel Data"
author: "Kodi Weatherholtz"
date: "April 25, 2016"
output:
  html_document:
    number_sections: true
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
---


```{r preamble, cache=FALSE, warning=FALSE, echo=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE,
                      warning = FALSE, 
                      message = FALSE,
                      dev = c('png', 'pdf', 'svg'),
                      fig.width = 9,
                      fig.height = 3)
```


# Data initialization
```{r data-initialization}

devtools::load_all()

# load relevant packages
library(dplyr)
library(tidyr)
library(mvtnorm)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(psych)
library(phonR) # contains functions for vowel normalization
library(Cairo) # for saving plots with special characters (e.g., IPA)


theme_1 <- theme_bw() +
  theme(panel.border = element_blank(),
        legend.position = "top",
        legend.background = element_rect(colour = "grey"),
        panel.grid.major.x = element_blank(), 
        panel.grid.minor.x = element_blank())


# load hVd vowel data from Nationwide Speech Project
data('nsp_vows', package='nspvowels')

# add Lobanov-normalized (z-scored) F1 and F2 values
nsp_vows <- nsp_vows %>%
  group_by(Talker) %>%
  mutate(
    F1.Lobanov = as.numeric(normLobanov(F1)),
    F2.Lobanov = as.numeric(normLobanov(F2)))
```

```{r}
print.data.frame(head(nsp_vows))

xtabs(~ Sex + Dialect, subset(nsp_vows, !duplicated(Talker)))

levels(nsp_vows$Vowel)
```

# Helper functions {.tabset .tabset-fade}
Click the tabs below to show the source code for each function.


## Calculate category probability based on specified distributional statistics
```{r get-category-probability}
# function for calculating probability of correct recognition 
# under a specific model/data.frame

getCategoryProbability = function(
  data_point,           # data point for which prob under category is sought
  model.data,           # df with the relevant multivariates for all categories
  model.category = NULL # relevant category for which probability is sought
) {
  # if a specific category is specified during the call, 
  # get probability of that category (involves recursive call 
  # to this function)
  if(!is.null(model.category)) {
    p =
      with(
        model.data %>%
          filter(Vowel == model.category),
        dmvnorm(
          data_point,
          c(F1.mean, F2.mean),
          covar2D(F1.var, F2.var, F1.F2.covar) # <<<<<<< here and throughout: this probably needs to be converted into a correlation?
        )
      )
    
    # posterior probability of data point under specified category, 
    # normalized by the summed probability of the data point 
    # under all categories
    pp = p / sum(getCategoryProbability(data_point = data_point, 
                                        model.data = model.data
                                        )
                 )
    
    # criterion rule: is probability of data point under specified 
    # category greater than the probability of that data point 
    # under any **other** category?
    cr = ifelse(p >
                  max(getCategoryProbability(
                    data_point = data_point,
                    model.data = subset(model.data, Vowel != model.category)
                  )
                  ),
                1,
                0)
    
    return(list(pp, cr))
    
    # if no category is specified during call, get vector of probabilities over
    # each category
  } else {                      
    m = model.data %>%
      rowwise() %>%
      do(
        p =
          dmvnorm(
            data_point,
            c(.$F1.mean, .$F2.mean),
            covar2D(.$F1.var, .$F2.var, .$F1.F2.covar)
          )
      ) %>%
      ungroup() %>%
      #summarise(p = sum(as.numeric(p)))
      mutate(p = as.numeric(p)) # <<<<<<<<<<< return vector of probabilities to allow (i) querying of this vetor (for criterion rule) and (ii) summing of this vector for normalization
    
    return(m$p)
  }
}
```


# Generative model parameters {.tabset .tabset-fade}
The NSP hVd vowel corpus only contains acoustic measurements for the first two formants. Thus, for the purposes of the current analysis, we assume vowel categories can be approximated as multivariate normal distributions in F~1~xF~2~ space. We start by identifying the parameters that define these multivariate distributions (i.e., F~1~ and F~2~ means, variances and covariance) at different levels of specificity: by talker, by gender, by dialect, by *both* gender and dialect, or marginalizing across all socio-indexical variables.

## raw F~1~xF~2~ distributional statistics
```{r generative-model-parameters}

speaker_model <- nsp_vows %>% group_by(Talker) %>% train_models()
gender_model <- nsp_vows %>% group_by(Sex) %>% train_models()
dialect_model <- nsp_vows %>% group_by(Dialect) %>% train_models()
genderByDialect_model <- nsp_vows %>% group_by(Sex, Dialect) %>% train_models()
marginal_model <- nsp_vows %>% group_by() %>% train_models()

```

## Lobanov-normalized (z-scored) F~1~xF~2~ distributional statistics
```{r}

train_models_lobanov <- function(d, ...) 
  train_models(d, formants = c("F1.Lobanov", "F2.Lobanov"), ...)

speaker_model_Ln <- 
  nsp_vows %>% group_by(Talker) %>% train_models_lobanov()
gender_model_Ln <-
  nsp_vows %>% group_by(Sex) %>% train_models_lobanov()
dialect_model_Ln <-
  nsp_vows %>% group_by(Dialect) %>% train_models_lobanov()
genderByDialect_model_Ln <-
  nsp_vows %>% group_by(Sex, Dialect) %>% train_models_lobanov()
marginal_model_Ln <-
  nsp_vows %>% group_by() %>% train_models_lobanov()


```

# Informativity with respect to cue distributions {.tabset .tabset-fade}
...

## Analysis code
```{r KL-divergence}

kl_from_marginal <- function(models, description, ref_models = marginal_model) {
  left_join(models, ref_models, by='Vowel') %>%
    mutate(KL = map2_dbl(model.x, model.y, nspvowels::KL_mods),
           KL.desc = description)
}

KL_talker <- speaker_model %>% kl_from_marginal("conditioned\non talker")
KL_gender <- gender_model %>% kl_from_marginal("conditioned\non gender")
KL_dialect <- dialect_model %>% kl_from_marginal("conditioned\non dialect")
KL_genderByDialect <- genderByDialect_model %>% kl_from_marginal("conditioned\non gender and dialect")

kl_from_marginal_lobanov <- 
  function(...) kl_from_marginal(..., ref_models = marginal_model_Ln)

KL_talker_Ln <-
  speaker_model_Ln %>% kl_from_marginal_lobanov("conditioned\non talker")
KL_gender_Ln <-
  gender_model_Ln %>% kl_from_marginal_lobanov("conditioned\non gender")
KL_dialect_Ln <-
  dialect_model_Ln %>% kl_from_marginal_lobanov("conditioned\non dialect")
KL_genderByDialect_Ln <-
  genderByDialect_model_Ln %>% kl_from_marginal_lobanov("conditioned\non gender and dialect")

```

## Graphing code
```{r, fig.height = 8}
library(gtools)
library(scales)

KL_combined <- bind_rows(KL_talker,
                         KL_gender,
                         KL_dialect,
                         KL_genderByDialect
                         )

KL_combined_Ln <- bind_rows(KL_talker_Ln,
                            KL_gender_Ln,
                            KL_dialect_Ln,
                            KL_genderByDialect_Ln
                            )

KL_legend_title <- "Difference between the marginal F1xF2 distribution and the\ncorresponding distribution _______________"

p_kl <- KL_combined %>%
  filter(!is.na(KL)) %>%
  ggplot(aes(x = Vowel,
             y = KL,
             colour = Vowel, fill = Vowel,
             group = KL.desc, alpha = KL.desc)) +
  stat_summary(fun.y = "mean", geom = "bar", 
               position = position_dodge(.9)) +
  stat_summary(fun.data = "mean_cl_boot", geom = "pointrange", 
               position = position_dodge(.9),
               alpha = 1, colour = "grey30") +
  stat_summary(fun.y = "mean", geom = "point", 
               position = position_dodge(.9),
               alpha = 1,
               show.legend = FALSE) +
  scale_y_continuous("KL divergence (in bits)", expand = c(0,0)) +
  scale_alpha_manual(KL_legend_title, values = c(.4, .6, .8, .95)) +
  guides(fill = FALSE, colour = FALSE,
         alpha = guide_legend(title.position = "top")) +
  coord_cartesian(ylim = c(0,6.3)) +
  geom_rangeframe(colour = "black", alpha = 1) +
  theme_1

p_kl_ln <- KL_combined_Ln %>%
  filter(!is.na(KL)) %>%
  ggplot(aes(x = Vowel,
             y = KL,
             colour = Vowel, fill = Vowel,
             group = KL.desc, alpha = KL.desc)) +
  stat_summary(fun.y = "mean", geom = "bar", 
               position = position_dodge(.9)) +
  stat_summary(fun.data = "mean_cl_boot", geom = "pointrange", 
               position = position_dodge(.9),
               alpha = 1, colour = "grey30") +
  stat_summary(fun.y = "mean", geom = "point", 
               position = position_dodge(.9),
               alpha = 1,
               show.legend = FALSE) +
  scale_y_continuous("KL divergence (in bits)", expand = c(0,0)) +
  scale_alpha_manual(KL_legend_title, values = c(.4, .6, .8, .95)) +
  guides(fill = FALSE, colour = FALSE,
         alpha = guide_legend(title.position = "top")) +
  coord_cartesian(ylim = c(0,6.3)) +
  geom_rangeframe(colour = "black", alpha = 1) +
  theme_1
```


## Graphs
```{r, fig.height = 8}
grobs <- ggplotGrob(p_kl + theme(legend.position="bottom"))$grobs
legend_b <- grobs[[which(sapply(grobs, function(x) x$name) == "guide-box")]]

plot_grid(legend_b, 
          p_kl + 
            theme(legend.position = "none"), 
          p_kl_ln + 
            theme(legend.position = "none"), 
          labels = c("", 
                     "A (input = F1xF2 (Hz))", 
                     "B (input = Lobanov-normalized F1xF2)"),
          label_size = 13,
          hjust = 0,
          vjust = 0,
          nrow = 3, 
          rel_heights = c(.2, 1, 1))

```



# Informativity with respect to categorization {.tabset .tabset-fade}
Here we calculate the probability of correctly categorizing each vowel token in the `nsp_vows` dataframe under different generative models:

**Generative models:**

1. marginal model: <br> p(vowel category | F~1~xF~2~) 

2. dialect-specific model: <br> p(vowel category | F~1~xF~2~, dialect)

3. gender-specific model: <br> p(vowel category | F~1~xF~2~, gender)

4. dialect- and gender-specific model: <br> p(vowel category | F~1~xF~2~, gender, dialect)

5. talker-specific model: <br> p(vowel category | F~1~xF~2~, talker identity)

**Assumptions:**

- categorization = selecting category with highest posterior probability, given the input
- uniform prior probability across vowels
- perfect knowledge of talker- or group-specific distributional statistics
- perfect certainty about gender/dialect/talker identity

## Analysis code
```{r prob-correct-under-each-generative-model}
## ----------------------------------------------
# calculate probability and log-odds correct for each 
# vowel token under the different models and store 
# the results in the same data.frame
## ----------------------------------------------

talker_class <-
  nsp_vows %>%
  classify_mods(speaker_model) %>%
  mutate(model = 'talker')

gender_class <-
  nsp_vows %>%
  classify_mods(gender_model) %>%
  mutate(model = 'gender')

dialect_class <-
  nsp_vows %>%
  classify_mods(dialect_model) %>%
  mutate(model = 'dialect')

genderByDialect_class <-
  nsp_vows %>%
  classify_mods(genderByDialect_model) %>%
  mutate(model = 'genderByDialect')

## requires a hack to create a dummy grouping variable.
marginal_class <-
  nsp_vows %>%
  mutate(dummy=1) %>%
  classify_mods(marginal_model %>% mutate(dummy=1) %>% group_by(dummy)) %>%
  mutate(model = 'marginal',
         dummy = NULL)

class_hz <- bind_rows(talker_class,
                      gender_class,
                      dialect_class,
                      genderByDialect_class,
                      marginal_class)

```

## Graphing code
```{r, fig.height = 8}
## --------------------------------- 
# define variables for quick conversion of factor levels

gen.model.t = c("marginal",
                "conditioned\non dialect",
                "conditioned\non gender",
                "conditioned\non dialect and gender",
                "conditioned\non talker identity")


model_names <- data_frame(model = c('marginal',
                                    'dialect',
                                    'gender',
                                    'genderByDialect',
                                    'talker'),
                          generative_model = factor(gen.model.t,
                                                    levels = gen.model.t))


## --------------------------------- 
# average probability of recognizing each vowel (using criterion rule)
# under various generative models
## --------------------------------- 

p_hz <- class_hz %>%
  rename(correct_recog = correct) %>%
  left_join(model_names)
  ggplot(aes(x = Vowel, 
             y = correct_recog, 
             fill = Vowel,
             colour = Vowel,
             group = generative_model,
             #colour = generative_model, 
             alpha = generative_model)) + 
  stat_summary(fun.y = "mean", geom = "bar", 
               position = position_dodge(.9)) +
  stat_summary(fun.data = "mean_cl_boot", geom = "pointrange", 
               position = position_dodge(.9),
               alpha = 1, colour = "grey30") +
  stat_summary(fun.y = "mean", geom = "point", 
               position = position_dodge(.9),
               aes(colour = Vowel),
               alpha = 1,
               show.legend = FALSE) +
  scale_y_continuous("Probability of correct recognition") +
  scale_alpha_manual(values = c(.2, .4, .6, .8, .95)) +
  guides(fill = FALSE, colour = FALSE) +
  coord_cartesian(ylim = c(.38, 1)) +
  geom_rangeframe(colour = "black", alpha = 1) +
  theme_1


p_Ln <- d %>%
  select(Talker, Vowel, one_of(gen.model.lobanov)) %>%
  gather(
    key = generative_model, 
    value = correct_recog, 
    ends_with("correct_recog")
    ) %>%
  mutate(
    generative_model = plyr::mapvalues(generative_model, 
                                       from = gen.model.lobanov,
                                       to = gen.model.t),
    generative_model = factor(generative_model, 
                              levels = gen.model.t)
    ) %>% 
  ggplot(aes(x = Vowel, 
             y = correct_recog, 
             fill = Vowel,
             colour = Vowel,
             group = generative_model,
             alpha = generative_model)) + 
  stat_summary(fun.y = "mean", geom = "bar", 
               position = position_dodge(.9)) +
  stat_summary(fun.data = "mean_cl_boot", geom = "pointrange", 
               position = position_dodge(.9),
               alpha = 1, colour = "grey30") +
  stat_summary(fun.y = "mean", geom = "point", 
               position = position_dodge(.9),
               aes(colour = Vowel),
               alpha = 1,
               show.legend = FALSE) +
  scale_y_continuous("Probability of correct recognition") +
  scale_alpha_manual(values = c(.2, .4, .6, .8, .95)) +
  guides(fill = FALSE, colour = FALSE) +
  coord_cartesian(ylim = c(.38, 1)) +
  geom_rangeframe(colour = "black", alpha = 1) +
  theme_1
```


## Graphs
```{r, fig.height = 8}
grobs <- ggplotGrob(p_hz + theme(legend.position="bottom"))$grobs
legend_b <- grobs[[which(sapply(grobs, function(x) x$name) == "guide-box")]]

plot_grid(legend_b, 
          p_hz + theme(legend.position = "none"), 
          p_Ln + theme(legend.position = "none"), 
          labels = c("", 
                     "A (input = F1xF2 (Hz))", 
                     "B (input = Lobanov-normalized F1xF2)"),
          label_size = 13,
          hjust = 0,
          vjust = 0.5,
          nrow = 3, 
          rel_heights = c(.2, 1, 1))

```


