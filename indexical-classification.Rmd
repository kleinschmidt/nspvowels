---
title: Inferring socio-indexical features
author: Dave Kleinschmidt
output:
  html_document:
    number_sections: true
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r preamble, cache=FALSE, message=FALSE, warning=FALSE, error=FALSE}

knitr::opts_chunk$set(cache=TRUE)

library(ggplot2)
library(magrittr)
library(tidyr)
library(dplyr)
library(devtools)
library(phonR) # contains functions for vowel normalization
load_all()

## data('nsp_vows', package='nspvowels')

nsp_vows <- nspvowels::nsp_vows

```

# The easy, bad way

## Train models

```{r train-models}

dialect_models <- nsp_vows %>% group_by(Dialect) %>% train_models()

```


## Test models

### Get models in analogous form to Vowel classification

For each group, want a list of models whose names are the classes. In this case, the "group" is the whole dataset, each "model" is a list of single-vowel models, and the class is Dialect.

```{r list-models}

dialect_model_list <-
  dialect_models %>%
  do(model=list_models(., 'Vowel')) %>%
  list_models('Dialect')

```

### Calculate likelihood for each token

Now we need to apply each of the Dialect models to the data.

```{r test-models}

d <- nsp_vows %>% ungroup()

#' @param data data.frame with columns F1 and F2 (passed to marginal_model_lhood)
#' @param model_list list of models to calculate likelihood
#' @return data.frame of likelihoods, with one column per model, one row per row
#' in data
apply_models <- function(data, model_list) {
  model_list %>%
    map(~ marginal_model_lhood(., formants_matrix(data))) %>%
    ## do.call(rbind, .) %>%
    ## t() %>%                            # matrix with Dialect as cols
    as_data_frame()                       # data frame with Dialect as cols
}

log_lhoods <- apply_models(ungroup(nsp_vows), dialect_model_list)

```

```{r grouped-lhood, eval=FALSE}
## Wrap in a tbl_df (to accomodate grouping
data_frame(data=list(d), models=list(dialect_model_list)) %>%
  mutate(log_lhoods = map2(data, models, apply_models))
```

### Aggregate likelihoods across tokens for each talker

```{r aggregate-lhood}

join_lhoods <- function(d, lhoods) {
  lhoods %>%
    mutate(id_ = row_number()) %>%
    gather(model, lhood, -id_) %>%
    inner_join(d %>% mutate(id_ = row_number()), by='id_')
}

summarise_posterior <- function(d) {
  d %>%
    group_by(Talker, Dialect, model) %>%
    summarise(lhood = sum(lhood)) %>%     # aggregate log-lhood within talkers
    # normalize to get posterior
    mutate(log_posterior = lhood - log_sum_exp(lhood),
           posterior = exp(log_posterior),
           posterior_choice = as.numeric(posterior == max(posterior)))
}

posteriors <- d %>% join_lhoods(log_lhoods) %>% summarise_posterior()

```

## Results

```{r talker-classification, fig.width=11, fig.height=5}

posteriors %>%
  ggplot(aes(x=Talker, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal() +
  facet_wrap(~ Dialect, scales='free')

```

```{r dialect-confusion-mat}

# continuous posterior probability
posteriors %>%
  group_by(Dialect, model) %>%
  summarise(posterior = mean(posterior)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal()

# categorical choice
posteriors %>%
  group_by(Dialect, model) %>%
  summarise(posterior_choice = mean(posterior_choice)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior_choice)) +
  geom_tile() +
  coord_equal()

```

# The harder, but correct way

That works pretty well (unsurprisingly, beacuse we're double dipping: testing on training data).

## Train models with cross-validation

Need to hold out each talker from training set.

```{r train-test-splits}

group_ = "Dialect"

# Train model for each talker, holding their data out.
# TODO: can be made much more efficient by only re-training the model for the
# matching dialect.
dialect_models_talker_held_out <-
  nsp_vows %$%
  unique(Talker) %>%
  data_frame(Talker = .,
             models = map(., ~ nsp_vows %>%
                               filter(Talker != .x)  %>%
                               group_by_(group_) %>%
                               train_models() %>%
                               do(model=list_models(., 'Vowel')) %>%
                               list_models(group_)
                          ))
  
# Combine data and models
posteriors_cv <-
  nsp_vows %>%
  group_by(Talker, Dialect) %>%
  nest() %>%
  left_join(dialect_models_talker_held_out) %>%
  mutate(lhoods = map2(data, models, apply_models),
         data = map2(data, lhoods, join_lhoods)) %>%
  unnest(data) %>%
  summarise_posterior()

## Test cross-validated models

```

## Results

### Single-talker classification

```{r loo-talker-classification, fig.width=11, fig.height=5}

posteriors_cv %>%
  ggplot(aes(x=Talker, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal() +
  facet_wrap(~ Dialect, scales='free')

```

Not too impressive. It looks like a lot of people are getting absorbed into Midland. Maybe not terribly surprising, given that 


### Dialect confusion

```{r loo-dialect-confusion-mat}

# continuous posterior probability
posteriors_cv %>%
  group_by(Dialect, model) %>%
  summarise(posterior = mean(posterior)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal()

# categorical choice
posteriors_cv %>%
  group_by(Dialect, model) %>%
  summarise(posterior_choice = mean(posterior_choice)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior_choice)) +
  geom_tile() +
  coord_equal()

```

Even though accuracy is above chance, it's not significantly so:

```{r loo-dialect-correct}

binomial_ci = function(p, x) qbeta(p, sum(x)+0.5, length(x)-sum(x)+0.5)

posteriors_cv %>%
  filter(Dialect == model) %>%
  ungroup() %>%
  summarise(posterior_choice_mean = mean(posterior_choice),
            posterior_choice_lo = binomial_ci(0.025, posterior_choice),
            posterior_choice_hi = binomial_ci(0.975, posterior_choice))

```

# Using normalized formants

The biggest differences between talkers' overall distributions come from gender, which is probably a big reason why the accuracy is so low here. Lobanov normalizing each talker's vowel space controls for most of variance from gender.

```{r lobanove-normalize}
nsp_vows_lob <- nspvowels::nsp_vows %>%
  group_by(Talker) %>%
  mutate_each(funs(normLobanov), F1:F2) %>%
  ungroup()
```

