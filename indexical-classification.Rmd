---
title: Inferring socio-indexical features
author: Dave Kleinschmidt
output:
  html_document:
    number_sections: true
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r preamble, cache=FALSE, message=FALSE, warning=FALSE, error=FALSE}

library(ggplot2)
library(magrittr)
library(tidyr)
library(dplyr)
library(phonR) # contains functions for vowel normalization

library(devtools)
load_all()

## data('nsp_vows', package='nspvowels')

nsp_vows <- nspvowels::nsp_vows %>% ungroup()

```

# Indexical classification

## Data: Normalized vs. non-normalized

The biggest differences between talkers' overall distributions come from gender, which is going to obscure systematic differences between dialect groups. Lobanov normalizing each talker's vowel space controls for most of variance from gender. So we'll do the analysis using both normalized and non-normalized data.

```{r lobanov-normalize}
nsp_vows_lob <- nspvowels::nsp_vows %>%
  group_by(Talker) %>%
  mutate_each(funs(normLobanov), F1:F2) %>%
  ungroup()
```

## Train and test models {.tabset .tabset-fade}

### Methods



1. For each talker, split data into __test set__ (only that talker's data) and __training set__ (everything but that talker's data)
2. Train models on training set: For each Dialect/Gender, compute each Vowel's mean and covariance matrix. This gives a list of vowel space mixture models for each Dialect/Gender.
3. Test models on test set. For each Dialect/Gender model $g$:
    * Compute the _marignal likelihood_ of each test observation $x_i$, $p(x_i | g)$, by taking the average likelihood of $x_i$ under each Vowel $j$: $p(x_i | g) = \sum_j p(x_i | \mathrm{Vowel}=j, g) \frac{1}{N_j}$
    * The overall likelihood of group $g$ is then the product of the individual test observation likelihoods $p(x | g) = \prod_i p(x_i | g)$.
    * The posterior probability of group $g$ is then proportional to this likelihood (assuming equal prior on the groups), and the actual posterior is computed by normalizing the likelihoods to sum to 1: $p(g | x) = \frac{p(x | g)}{\sum_g p(x|g)}$


### Run it

```{r train-test-models-cv, cache=TRUE}

datasets <- data_frame(dataset = c('Un-normalized', 'Lobanov Normalized'),
                       data = list(nsp_vows, nsp_vows_lob))

index_models <-
  cross_d(list(dataset = datasets$dataset,
               grouping = c('Dialect', 'Sex', 'Dialect_Sex', 'Marginal'))) %>%
  left_join(datasets) %>%
  mutate(data = map(data, . %>% mutate(Marginal='all',
                                       Dialect_Sex = paste(Sex, Dialect, sep='_')))) %>%
  mutate(trained = map2(data, grouping, train_models_indexical_with_holdout),
         posteriors = map(trained, classify_indexical_with_holdout))

index_class <-
  index_models %>%
  unnest(map2(posteriors, grouping,
              ~ rename_(.x, 'group' = .y)))

```

## Results {.tabset .tabset-fade}

With the exception of dialect on un-normalized vowels, accuracy is reasonably good (well above chance in the other cases).  Even (surprisingly) for decoding gender with normalized vowels. The problem with un-normalized dialect classification appears to be that just about everyone gets lumped into Midland.

It's hard to read too much into the confusions since the sample size is so small (eight talkers per group). But, with that caveat in mind, the accuracy is best (around 50%) for Mid-Atlantic, North, and South. West is often confused for New England and South, 

### Overall accuracy

```{r acc-summary, results='asis', echo=FALSE}

binomial_ci = function(p, x) qbeta(p, sum(x)+0.5, length(x)-sum(x)+0.5)

index_class %>%
  group_by(grouping, dataset, Talker) %>%
  filter(posterior == max(posterior)) %>%
  summarise(acc = mean(model == group)) %>%
  summarise(acc_mean = mean(acc),
            acc_lo = binomial_ci(0.025, acc),
            acc_hi = binomial_ci(0.975, acc)) %>%
  knitr::kable(digits=2)

```

```{r acc-plots, fig.width=4.3, fig.height=4.3, echo=FALSE}

agg_color <- 'red'

chance <-
  index_class %>%
  group_by(grouping, group) %>%
  summarise() %>%
  tally() %>%
  mutate(chance = 1/n)

index_class %>%
  group_by(dataset, grouping, Talker) %>%
  filter(group == model) %>%
  ggplot(aes(x=dataset, y=posterior)) +
  geom_hline(data = chance, aes(yintercept = chance),
             linetype=3, color=agg_color) +
  ## geom_bar(stat='summary', fun.y=mean) +
  geom_point(position=position_jitter(w=0.5), alpha=0.2) +
  geom_pointrange(stat='summary', fun.data=mean_cl_boot, color=agg_color) +
  facet_grid(.~grouping, scales='free', space='free') +
  labs(y = 'Posterior probability of correct group') +
  theme(axis.text.x = element_text(angle=20, hjust=1))

```

### Accuracy by group

```{r acc-by-group-summary, results='asis', echo=FALSE}

binomial_ci = function(p, x) qbeta(p, sum(x)+0.5, length(x)-sum(x)+0.5)

index_class %>%
  group_by(grouping, dataset, group, Talker) %>%
  filter(posterior == max(posterior)) %>%
  summarise(acc = mean(model == group)) %>%
  summarise(acc_mean = mean(acc),
            acc_lo = binomial_ci(0.025, acc),
            acc_hi = binomial_ci(0.975, acc)) %>%
  knitr::kable(digits=2)

```

```{r acc-by-group-plots, fig.width=8, fig.height=4.3, echo=FALSE}

index_class %>%
  group_by(dataset, grouping, Talker) %>%
  filter(group == model) %>%
  ggplot(aes(x=group, y=posterior)) +
  geom_hline(data = chance, aes(yintercept = chance),
             linetype=3, color=agg_color) +
  ## geom_bar(stat='summary', fun.y=mean) +
  geom_point(position=position_jitter(w=0.5), alpha=0.2) +
  geom_pointrange(stat='summary', fun.data=mean_cl_boot, color=agg_color) +
  facet_grid(.~grouping+dataset, scales='free', space='free') +
  labs(y = 'Posterior probability of correct group') +
  theme(axis.text.x = element_text(angle=45, hjust=1))

```

### Dialect confusion matrices

```{r dialect-confusion-mats, fig.width=8, fig.height=4.3, echo=FALSE}

index_class %>%
  filter(grouping == 'Dialect') %>%
  group_by(group, dataset, model) %>%
  summarise(posterior = mean(posterior)) %>%
  ggplot(aes(x=group, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal() +
  facet_grid(.~dataset) +
  theme(axis.text = element_text(angle=45, hjust=1))

```

### Single-talker dialect classification

```{r talker-dialect-classification, fig.width=11, fig.height=3.1, echo=FALSE}

index_class %>%
  filter(grouping == 'Dialect') %>%
  ggplot(aes(x=Talker, y=model, fill=posterior)) +
  geom_tile() +
  facet_grid(dataset ~ group, scales='free_x') +
  coord_equal()

```

# Joint vowel-indexical classification

## Methods {.tabset .tabset-fade}

We want to infer both the Vowel $v_i$ and the indexical group $g$, given some observations $x_i$. There are at least two ways to do this. Either way, we want to do it separately for each talker, making sure to use the right training/test data.

### Factorized

We can factor the joint posterior $p(v_i, g | x_i)$ into things we already know how to do:

$p(v, g | x) = p(v | x, g) p(g | x)$

That is, the probability of each vowel, given group (from the original analysis), weighted by how likely the group is given the tokens (from the first part here). We can compute each of these separately and them combine.

#### Conditional posterior of each vowel, given group

```{r vowel-given-group, cache=TRUE}
## 1. Likelihood of each token under each vowel for each dialect model
#' Compute posterior vowel category conditional on group
#'
#' Applies classify_vowels to test data for each group_model.
#'
#' @param data_test test data to calculate posteriors for
#' @param group_models named list of group models, each of which is a named list
#'   of vowel models
#' @return data frame with one row per data_test row x group x vowel model, with
#'   added columns group_model (name of group model), vowel_model (name of vowel
#'   model), lhood p(x | vowel_model, group_model), posterior (p(vowel_model |
#'   x, group_model)).
compute_vowel_post_given_group <- function(data_test, group_models) {
  group_models %>%
    map(~ unlist_models(., 'Vowel')) %>%
    map(~ classify_vowels(data_test, .)) %>%
    data_frame(group_model=names(.),
               x=.) %>%
    unnest(x) %>%
    rename(vowel_model=model)
}

```

#### Marginal posterior of group

```{r group-marginal, cache=TRUE}

## 2. Posterior prob for each dialect model (entry in models)
#' Compute marginal posterior of each group from join vowel/group likelihood
#'
#' @param group_vowel_posteriors data frame with columns group_model, Vowel,
#'   Token, lhood. (that is, output from compute_vowel_post_given_group).
#' @return data frame with one row per group, and columns group_model,
#'   log_lhood, log_posterior, and posterior
compute_group_marginal_post <- function(group_vowel_posteriors) {
  group_vowel_posteriors %>%
    group_by(group_model, Vowel, Token) %>%
    mutate(log_lhood =log(lhood)) %>%
    summarise(log_lhood = log_mean_exp(log_lhood)) %>%
    group_by(group_model) %>%
    summarise(log_lhood = sum(log_lhood)) %>%
    mutate(log_posterior = log_lhood - log_sum_exp(log_lhood),
           posterior = exp(log_posterior))
}

```

#### Combine to get joint posterior

```{r joint-posterior, cache=TRUE}

#' Combine vowel | group posteriors with group posteriors
#'
#' @param group_vowel_posteriors vowel posterior probabilities conditional on
#'   group, in the form of a data frame with at least columns vowel_model,
#'   group_model, and posterior (e.g., output of compute_vowel_post_given_group)
#' @param group_posterior marginal group posterior probabilities, in the form of
#'   a data frame with columns group_model and log_posterior (e.g., output of
#'   compute_group_marginal_posterior)
#' @return a data frame with the joint posterior of vowel category and group, in
#'   posterior and log_posterior.
compute_joint_vowel_group_post <- function(group_vowel_posteriors, group_posteriors) {
  group_posteriors %>%
    select(group_model, group_log_posterior=log_posterior) %>%
    inner_join(group_vowel_posteriors, by = 'group_model') %>%
    mutate(log_posterior = log(posterior) + group_log_posterior,
           posterior = exp(log_posterior))
}
```



#### Do it

```{r compute-joint-posteriors, cache=TRUE, dependson=c('train-test-models-cv',-1,-2,-3)}

trained_to_joint_post <- function(trained) {
  trained %>%
  mutate(group_vowel_posteriors = map2(data_test, models,
                                       compute_vowel_post_given_group),
         group_posteriors = map(group_vowel_posteriors,
                                compute_group_marginal_post)
         ) %>%
  unnest(map2(group_vowel_posteriors, group_posteriors,
              compute_joint_vowel_group_post))
}
  

index_models %<>%
  mutate(joint_posteriors = map(trained, trained_to_joint_post))

joint_class <-
  index_models %>%
  unnest(map2(joint_posteriors, grouping, ~ rename_(.x, 'group'=.y)))

```

### Directly

Alternatively, you could just do it directly, by evaluating the likelihood of each vowel + dialect and then normalizing appropriately. 

$p(v, g | x) \propto p(x | v, g) p(v, g)$

The normalization is the tricky bit (since the effect of $g$ is pooled across all the tokens from a talker), and I think the factorized way is a bit easier.

## Comparison to when group is known

The real question is how much performance improves when you _know_ the right group. Again, it's important to evaluate this using cross validation: hold out one talker's data, group-level models on the others, and then test. 

We've already calculated this above, just need to filter by `group == group_model` using the `joint_class` and re-normalize the posteriors correctly:

```{r classify-with-known-group, cache=TRUE, dependson='train-test-models-cv'}

# leaving this here for posterity: 
#' Classify vowels assuming group is known
#'
#' @param trained trained models df
#' @param grouping name of grouping column in trained
#' @return test dataframe plus output of classify_vowels
vowel_post_true_group <- function(trained, grouping) {
  trained %>%
    rename_('group' = grouping) %>%
    mutate(model = map2(models, group, ~ .x[[.y]]) %>%
             map(. %>% unlist_models('Vowel')),
           vowel_class = map2(data_test, model, classify_vowels)) %>%
    unnest(vowel_class) %>%
    rename_(.dots = set_names('group', grouping))
}

true_group_class <-
  joint_class %>%
  filter(group == group_model,
         grouping != 'Marginal') %>%
  group_by(dataset, grouping, Talker, group, Vowel, Token) %>%
  mutate(log_lhood = log(lhood),
         log_posterior = log_lhood - log_sum_exp(log_lhood),
         posterior = exp(log_posterior),
         posterior_choice = posterior == max(posterior)) %>%
  mutate(group_is = 'Known')

```



## Results {.tabset}

For each level of gropuing, we have two sets of results:

1. The _marginal category probabilities_ of each token, which assumes that the group label is unknown and listeners need to simultaneously infer the group _and_ the categories. Hence, this is the weighted average of the probabilities assigned under each group, weighted by the overall probability of that group (given all the tokens).
2. The _true group category probabilities_ of each token, which assumes that the listener _knows_ the true category. 

For the marginal model, these two are equivalent.

We can look at these in two ways: the full _confusion matrix_ of vowels, and the _probability of correct recognition_ under each scenario.

```{r combine-joint-and-true}


marginal_vowel_class <- joint_class %>%
  group_by(grouping, dataset, group, Talker) %>%
  group_by(Vowel, Token, vowel_model, add=TRUE) %>%
  ## marginalize out group_model:
  summarise(log_posterior = log_sum_exp(log_posterior),
            posterior = exp(log_posterior)) %>%
  mutate(posterior_choice = posterior == max(posterior)) %>%
  ungroup() %>%
  mutate(group_is = ifelse(grouping=='Marginal',
                           NA,
                           'Inferred'))

grouping_levels <-
  c('Marginal',
    'Dialect',
    'Sex',
    'Dialect_Sex')

vowel_class <-
  marginal_vowel_class %>%
  bind_rows(true_group_class) %>%
  mutate(grouping = factor(grouping, levels=grouping_levels),
         group_is = factor(group_is, levels=c('Inferred', 'Known')),
         vowel_model = factor(vowel_model, levels = levels(Vowel)))
  
## check that all posteriors over vowel_model sum to 1:
vowel_class %>%
  group_by(grouping, group_is, dataset, group, Talker, Vowel, Token) %>%
  summarise(sum_post = sum(posterior)) %$%
  assert_that(all.equal(sum_post, rep(1, length(sum_post))))

vowel_acc <-
  vowel_class %>%
  filter(posterior_choice) %>%
  mutate(accuracy = Vowel == vowel_model)
  

```

### Vowel confusion matrices

Vowel confusion matrices, split out by grouping factor and whether group is known or inferred. 

```{r joint-dialect-vowel-confusions, fig.width=10, cache=TRUE, dependson='compute-joint-posteriors'}

vowel_class %>%
  ## get cross-categorization probabilities for each vowel category (averaging
  ## over tokens):
  group_by(dataset, grouping, group_is, Vowel, vowel_model) %>% 
  summarise(posterior = mean(posterior),
            log_posterior = log_mean_exp(log_posterior)) %>%
  ggplot(aes(x=Vowel, y=vowel_model, fill=posterior)) +
  geom_tile() + coord_equal() +
  scale_fill_gradient(limits=c(0,1)) +
  facet_grid(dataset ~ grouping + group_is)

```

### Probability of correct recognition (accuracy)

#### Average probability of correct recognition for each vowel.

```{r joint-group-vowel-accuracy, cache=TRUE, dependson='compute-joint-posteriors'}

pd <- function() position_dodge(w=0.9)

vowel_acc %>%
  group_by(grouping, group_is, dataset, group, Talker, Vowel) %>%
  summarise(accuracy = mean(accuracy)) %>%
  ggplot(aes(x=Vowel, y=accuracy, fill=grouping, color=grouping,
             group=daver::paste_factors(grouping, group_is))) +
  geom_bar(aes(alpha=group_is), stat='summary', fun.y=mean, position=pd()) +
  geom_linerange(stat='summary', fun.data=mean_cl_boot, position=pd()) +
  facet_grid(dataset ~ .)

```

This is a little odd: in many (most?) cases, knowing the true group actually _hurts_ you, versus inferring the group. Also, in almost no cases does conditioning on both dialect and gender do you any good whatsoever. So it looks like the earlier analysis was purely a result of double-dipping :(  This is going to take some re-thinking for writing it up.

At a high level, what this reflects is that talkers with the same dialect are not necessarily more similar to each other in terms of their category-specific distributions. The overall distributions (ignoring the category identity) are similar enough (that is, can decode dialect, at least from normalized formants). And it might be the case that overall similarity (again, ignoring category) is correlated with good vowel categorization, which would lead to the marginal accuracy being higher.

#### Overall probability of correct recognition across vowels

```{r joint-group-accuracy, cache=TRUE, dependson='compute-joint-posteriors'}

pd <- function() position_dodge(w=0.9)

vowel_acc %>%
  group_by(grouping, group_is, dataset, group, Talker) %>%
  summarise(accuracy = mean(accuracy)) %>%
  ggplot(aes(x=1,
             y=accuracy, fill=grouping, color=grouping,
             group=daver::paste_factors(grouping, group_is))) +
  geom_bar(aes(alpha=group_is), stat='summary', fun.y=mean, position=pd()) +
  geom_linerange(stat='summary', fun.data=mean_cl_boot, position=pd()) +
  facet_grid(.~dataset)

```

Another thing that jumps out: Dialect doesn't really help above Marginal, and Dialec+Gender is actually _worse_ overall than Gender.

Both this and the finding that known is worse than inferred might reflect an overtraining thing. More specific groups have fewer talkers and more instability in the estimate of the true underlying distribution. Similarly, the true group has one less talker because the test talker is held out. 

One way to get around this might be to use individual talker models to classify the held out talker. Then at least you're not suffering from weirdly high variance distributions that come from a small number of wildly different talkers.

Finally: better performance might be achieved with a hierarchical model that infer the talker-specific distributions using a group-level prior. This would require

1. Estimating the distribution of means/covariance matrices for each vowel in each group. (Either sampling or MLE/MAP estimate)
2. Jointly estimating category labels and talker distributions under each group.
3. ...Profit? It's not clear how the marginalization would work. Might just be best off running a Stan model for each test-training split... Simultaneously infer test talker's group, vowel categories, and parameters, along with the group-level priors. This is going to require a TON of time/storage though.

### Vowel accuracy by group

```{r vowel-acc-by-group}

vowel_acc %>%
  group_by(grouping, dataset, group, Talker) %>%
  summarise(accuracy = mean(accuracy)) %>%
  ggplot(aes(x=group, y=accuracy, group=grouping)) +
  geom_point(alpha=0.2, position=position_jitter(w=0.5)) +
  geom_pointrange(stat='summary', fun.data=mean_cl_boot, color='red') +
  facet_grid(dataset ~ grouping, space='free_x', scales='free_x') +
  theme(axis.text.x = element_text(angle=45, hjust=1))

```

# Appendix: the danger of double dipping

It's important to not test on training data, especially when your sample size is small. In this case, that's because if you include a talker's data when you train the group-level models, group-level distributions for that talker's group are much more similar to that talker's own distributions.

## Train models

```{r train-models}

dialect_models <- nsp_vows %>% group_by(Dialect) %>% train_models()

```


## Test models

### Get models in analogous form to Vowel classification

For each group, want a list of models whose names are the classes. In this case, the "group" is the whole dataset, each "model" is a list of single-vowel models, and the class is Dialect.

```{r list-models}

dialect_model_list <-
  dialect_models %>%
  do(model=list_models(., 'Vowel')) %>%
  list_models('Dialect')

```

### Calculate likelihood for each token

Now we need to apply each of the Dialect models to the data.

```{r test-models}

d <- nsp_vows %>% ungroup()

log_lhoods <- apply_model_list(ungroup(nsp_vows), dialect_model_list,
                               marginal_model_lhood)

```

```{r grouped-lhood, eval=FALSE}
## (Could also wrap in a tbl_df (to accomodate grouping))
data_frame(data=list(d), models=list(dialect_model_list)) %>%
  mutate(log_lhoods = map2(data, models, apply_models))
```

### Aggregate likelihoods across tokens for each talker

```{r aggregate-lhood}

join_lhoods <- function(d, lhoods) {
  lhoods %>%
    mutate(id_ = row_number()) %>%
    gather(model, lhood, -id_) %>%
    inner_join(d %>% mutate(id_ = row_number()), by='id_')
}

summarise_posterior <- function(d) {
  d %>%
    group_by(Talker, Dialect, model) %>%
    summarise(lhood = sum(lhood)) %>%     # aggregate log-lhood within talkers
    # normalize to get posterior
    mutate(log_posterior = lhood - log_sum_exp(lhood),
           posterior = exp(log_posterior),
           posterior_choice = as.numeric(posterior == max(posterior)))
}

posteriors <- d %>% join_lhoods(log_lhoods) %>% summarise_posterior()

```

## Results

```{r talker-classification, fig.width=11, fig.height=5, echo=FALSE}

posteriors %>%
  ggplot(aes(x=Talker, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal() +
  facet_wrap(~ Dialect, scales='free')

```

```{r dialect-confusion-mat, echo=FALSE}

# continuous posterior probability
posteriors %>%
  group_by(Dialect, model) %>%
  summarise(posterior = mean(posterior)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal()

# categorical choice
posteriors %>%
  group_by(Dialect, model) %>%
  summarise(posterior_choice = mean(posterior_choice)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior_choice)) +
  geom_tile() +
  coord_equal()

```
