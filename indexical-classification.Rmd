---
title: Inferring socio-indexical features
author: Dave Kleinschmidt
---

```{r preamble, cache=FALSE, message=FALSE, warning=FALSE, error=FALSE}

knitr::opts_chunk$set(cache=TRUE)

library(ggplot2)
library(magrittr)
library(tidyr)
library(dplyr)
library(devtools)
load_all()

data('nsp_vows', package='nspvowels')

```


## Train models

```{r train-models}

dialect_models <- nsp_vows %>% group_by(Dialect) %>% train_models()

```


## Test models

### Get models in analogous form to Vowel classification

For each group, want a list of models whose names are the classes. In this case, the "group" is the whole dataset, each "model" is a list of single-vowel models, and the class is Dialect.

```{r list-models}

dialect_model_list <-
  dialect_models %>%
  do(model=list_models(., 'Vowel')) %>%
  list_models('Dialect')

```

### Calculate likelihood for each token

Now we need to apply each of the Dialect models to the data.

```{r test-models}

d <- nsp_vows %>% ungroup()

#' @param data data.frame with columns F1 and F2 (passed to marginal_model_lhood)
#' @param model_list list of models to calculate likelihood
#' @return data.frame of likelihoods, with one column per model, one row per row
#' in data
apply_models <- function(data, model_list) {
  model_list %>%
    map(~ marginal_model_lhood(., formants_matrix(data))) %>%
    ## do.call(rbind, .) %>%
    ## t() %>%                            # matrix with Dialect as cols
    as_data_frame()                       # data frame with Dialect as cols
}

log_lhoods <- apply_models(ungroup(nsp_vows), dialect_model_list)

```

```{r grouped-lhood, eval=FALSE}
## Wrap in a tbl_df (to accomodate grouping
data_frame(data=list(d), models=list(dialect_model_list)) %>%
  mutate(log_lhoods = map2(data, models, apply_models))
```

### Aggregate likelihoods across tokens for each talker

```{r aggregate-lhood}

join_lhoods <- function(d, lhoods) {
  lhoods %>%
    mutate(id_ = row_number()) %>%
    gather(model, lhood, -id_) %>%
    inner_join(d %>% mutate(id_ = row_number()), by='id_')
}

summarise_posterior <- function(d) {
  d %>%
    group_by(Talker, Dialect, model) %>%
    summarise(lhood = sum(lhood)) %>%     # aggregate log-lhood within talkers
    # normalize to get posterior
    mutate(log_posterior = lhood - log_sum_exp(lhood),
           posterior = exp(log_posterior),
           posterior_choice = as.numeric(posterior == max(posterior)))
}

posteriors <- d %>% join_lhoods(log_lhoods) %>% summarise_posterior()

```

```{r talker-classification, fig.width=11, fig.height=5}

posteriors %>%
  ggplot(aes(x=Talker, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal() +
  facet_wrap(~ Dialect, scales='free')

```

```{r dialect-confusion-mat}

# continuous posterior probability
posteriors %>%
  group_by(Dialect, model) %>%
  summarise(posterior = mean(posterior)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal()

# categorical choice
posteriors %>%
  group_by(Dialect, model) %>%
  summarise(posterior_choice = mean(posterior_choice)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior_choice)) +
  geom_tile() +
  coord_equal()

```



Works pretty well (unsurprisingly, beacuse we're double dipping: testing on training data).

## Cross-validation

Need to hold out each talker from training set.

```{r train-test-splits}

group_ = "Dialect"

# Train model for each talker, holding their data out.
# TODO: can be made much more efficient by only re-training the model for the
# matching dialect.
dialect_models_talker_held_out <-
  nsp_vows %$%
  unique(Talker) %>%
  data_frame(Talker = .,
             models = map(., ~ nsp_vows %>%
                               filter(Talker != .x)  %>%
                               group_by_(group_) %>%
                               train_models() %>%
                               do(model=list_models(., 'Vowel')) %>%
                               list_models(group_)
                          ))
  
# Combine data and models
posteriors_cv <-
  nsp_vows %>%
  group_by(Talker, Dialect) %>%
  nest() %>%
  left_join(dialect_models_talker_held_out) %>%
  mutate(lhoods = map2(data, models, apply_models),
         data = map2(data, lhoods, join_lhoods)) %>%
  unnest(data) %>%
  summarise_posterior()

```

Not too impressive. It looks like a lot of people are getting absorbed into Midland.

```{r loo-talker-classification, fig.width=11, fig.height=5}

posteriors_cv %>%
  ggplot(aes(x=Talker, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal() +
  facet_wrap(~ Dialect, scales='free')

```


```{r loo-dialect-confusion-mat}

# continuous posterior probability
posteriors_cv %>%
  group_by(Dialect, model) %>%
  summarise(posterior = mean(posterior)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal()

# categorical choice
posteriors_cv %>%
  group_by(Dialect, model) %>%
  summarise(posterior_choice = mean(posterior_choice)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior_choice)) +
  geom_tile() +
  coord_equal()

```

```{r loo-dialect-correct}

binomial_ci = function(p, x) qbeta(p, sum(x)+0.5, length(x)-sum(x)+0.5)

posteriors_cv %>%
  filter(Dialect == model) %>%
  ungroup() %>%
  summarise(posterior_choice_mean = mean(posterior_choice),
            posterior_choice_lo = binomial_ci(0.025, posterior_choice),
            posterior_choice_hi = binomial_ci(0.975, posterior_choice))

```
