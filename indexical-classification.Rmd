---
title: Inferring socio-indexical features
author: Dave Kleinschmidt
---

```{r preamble, cache=FALSE, message=FALSE, warning=FALSE, error=FALSE}

library(ggplot2)
library(devtools)
load_all()

data('nsp_vows', package='nspvowels')

```


## Train models

```{r train-models}

dialect_models <- nsp_vows %>% group_by(Dialect) %>% train_models()

```


## Test models

### Get models in analogous form to Vowel classification

For each group, want a list of models whose names are the classes. In this case, the "group" is the whole dataset, each "model" is a list of single-vowel models, and the class is Dialect.

```{r list-models}

dialect_model_list <-
  dialect_models %>%
  do(model=list_models(., 'Vowel')) %>%
  list_models('Dialect')

```

### Calculate likelihood for each token

Now we need to apply each of the Dialect models to the data.

```{r test-models}

d <- nsp_vows %>% ungroup()

#' @param data data.frame with columns F1 and F2 (passed to marginal_model_lhood)
#' @param model_list list of models to calculate likelihood
#' @return data.frame of likelihoods, with one column per model, one row per row
#' in data
apply_models <- function(data, model_list) {
  model_list %>%
    map(~ marginal_model_lhood(., formants_matrix(data))) %>%
    ## do.call(rbind, .) %>%
    ## t() %>%                            # matrix with Dialect as cols
    as_data_frame()                       # data frame with Dialect as cols
}

log_lhoods <- apply_models(ungroup(nsp_vows), dialect_model_list)

```

```{r grouped-lhood, eval=FALSE}
## Wrap in a tbl_df (to accomodate grouping
data_frame(data=list(d), models=list(dialect_model_list)) %>%
  mutate(log_lhoods = map2(data, models, apply_models))
```

### Aggregate likelihoods across tokens for each talker

```{r aggregate-lhood}

posteriors <- 
  lhoods %>%
  mutate(id_ = row_number()) %>%
  gather(model, lhood, -id_) %>%
  inner_join(d %>% mutate(id_ = row_number())) %>%
  group_by(Talker, Dialect, model) %>%
  summarise(lhood = sum(lhood)) %>%     # aggregate log-lhood within talkers
                                        # normalize to get posterior
  mutate(log_posterior = lhood - log_sum_exp(lhood),
         posterior = exp(log_posterior),
         posterior_choice = as.numeric(posterior == max(posterior)))

# continuous posterior probability
posteriors %>%
  group_by(Dialect, model) %>%
  summarise(posterior = mean(posterior)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior)) +
  geom_tile() +
  coord_equal()

# categorical choice
posteriors %>%
  group_by(Dialect, model) %>%
  summarise(posterior_choice = mean(posterior_choice)) %>%
  ggplot(aes(x=Dialect, y=model, fill=posterior_choice)) +
  geom_tile() +
  coord_equal()

```

Works pretty well (unsurprisingly, beacuse we're double dipping: testing on training data).
